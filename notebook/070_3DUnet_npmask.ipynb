{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "from helpers import *\n",
    "from dataset import *\n",
    "from model2_for48 import *\n",
    "from czii_helper import *\n",
    "from helpers_3Dunet import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,  \n",
    "    AsDiscrete,  \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    ")\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBAG = False\n",
    "#DEBAG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'local'\n",
    "valid_dir = '../input/czii-cryo-et-object-identification/train'\n",
    "\n",
    "cfg = dotdict(\n",
    "    arch ='resnet34d',\n",
    "    checkpoint=\\\n",
    "    '/kaggle/input/hengck-czii-cryo-et-weights-01/resnet34d-00010164-extern.pth',\n",
    "   # '/kaggle/input/hengck-czii-cryo-et-weights-01/resnet34d-aug-noise-00003956.pth',\n",
    "       #  '/kaggle/input/hengck-czii-cryo-et-weights-01/resnet34d-00002300.pth',\n",
    "       # '/kaggle/input/hengck-czii-cryo-et-weights-01/00003531.pth',\n",
    "    threshold={ \n",
    "        'apo-ferritin': 0.05,\n",
    "        'beta-amylase': 0.05,\n",
    "        'beta-galactosidase': 0.05,\n",
    "        'ribosome': 0.05,\n",
    "        'thyroglobulin': 0.05,\n",
    "        'virus-like-particle': 0.05,\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/czii-cryo-et-object-identification/train/static/ExperimentRuns/'\n",
    "mask_dir = '../input/czii-cryo-et-object-identification/train/overlay/ExperimentRuns/'\n",
    "TRAIN_DATA_DIR = \"../input/mask\"\n",
    "\n",
    "#diff =[\"denoised\",\"isonetcorrected\",\"wbp\",\"ctfdeconvolved\"]\n",
    "#diff =[\"denoised\",\"isonetcorrected\",\"wbp\",\"ctfdeconvolved\",\"denoised\"]\n",
    "diff =[\"denoised\"]\n",
    "\n",
    "valid_id = ['TS_99_9', \"TS_6_4\", \"TS_6_6\", \"TS_69_2\", \"TS_73_6\", \"TS_86_3\"]\n",
    "if DEBAG:\n",
    "    valid_id = [\"TS_5_4\"]\n",
    "test_id = [\"TS_5_4\"]\n",
    "\n",
    "train_files = []\n",
    "valid_files = []\n",
    "\n",
    "for name in valid_id:\n",
    "    image = read_one_data(name, train_dir)\n",
    "    label = np.load(f\"{TRAIN_DATA_DIR}/train_label_{name}.npy\")\n",
    "\n",
    "    train_files.append({\"image\": image, \"label\": label})\n",
    "    \n",
    "\n",
    "for name in test_id:\n",
    "    image = read_one_data(name, train_dir)\n",
    "    label = np.load(f\"{TRAIN_DATA_DIR}/train_label_{name}.npy\")\n",
    "\n",
    "    valid_files.append({\"image\": image, \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 6/6 [00:00<00:00, 11.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n",
    "\n",
    "raw_train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "\n",
    "my_num_samples = 16\n",
    "train_batch_size = 32\n",
    "\n",
    "# Random transforms to be applied during training\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[96, 96, 96],\n",
    "        num_classes=7,\n",
    "        num_samples=my_num_samples\n",
    "    ),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),    \n",
    "])\n",
    "\n",
    "train_ds = Dataset(data=raw_train_ds, transform=random_transforms)\n",
    "\n",
    "\n",
    "# DataLoader remains the same\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 98/98 [00:00<00:00, 308.09it/s]\n"
     ]
    }
   ],
   "source": [
    "val_images,val_labels = [dcts['image'] for dcts in valid_files],[dcts['label'] for dcts in valid_files]\n",
    "\n",
    "val_image_patches, _ = extract_3d_patches_minimal_overlap(val_images, 96)\n",
    "val_label_patches, _ = extract_3d_patches_minimal_overlap(val_labels, 96)\n",
    "\n",
    "val_patched_data = [{\"image\": img, \"label\": lbl} for img, lbl in zip(val_image_patches, val_label_patches)]\n",
    "\n",
    "\n",
    "valid_ds = CacheDataset(data=val_patched_data, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "\n",
    "valid_batch_size = 16\n",
    "# DataLoader remains the same\n",
    "valid_loader = DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=valid_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.losses import TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        spatial_dims: int = 3,\n",
    "        in_channels: int = 1,\n",
    "        out_channels: int = 7,\n",
    "        channels: Union[Tuple[int, ...], List[int]] = (48, 64, 80, 80),\n",
    "        strides: Union[Tuple[int, ...], List[int]] = (2, 2, 1),\n",
    "        num_res_units: int = 1,\n",
    "        lr: float=1e-3):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = UNet(\n",
    "            spatial_dims=self.hparams.spatial_dims,\n",
    "            in_channels=self.hparams.in_channels,\n",
    "            out_channels=self.hparams.out_channels,\n",
    "            channels=self.hparams.channels,\n",
    "            strides=self.hparams.strides,\n",
    "            num_res_units=self.hparams.num_res_units,\n",
    "        )\n",
    "        self.loss_fn = TverskyLoss(include_background=True, to_onehot_y=True, softmax=True)  # softmax=True for multiclass\n",
    "        self.metric_fn = DiceMetric(include_background=False, reduction=\"mean\", ignore_empty=True)\n",
    "\n",
    "        self.train_loss = 0\n",
    "        self.val_metric = 0\n",
    "        self.num_train_batch = 0\n",
    "        self.num_val_batch = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch['image'], batch['label']\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.train_loss += loss\n",
    "        self.num_train_batch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        loss_per_epoch = self.train_loss/self.num_train_batch\n",
    "        #print(f\"Epoch {self.current_epoch} - Average Train Loss: {loss_per_epoch:.4f}\")\n",
    "        self.log('train_loss', loss_per_epoch, prog_bar=True)\n",
    "        self.train_loss = 0\n",
    "        self.num_train_batch = 0\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        with torch.no_grad(): # This ensures that gradients are not stored in memory\n",
    "            x, y = batch['image'], batch['label']\n",
    "            y_hat = self(x)\n",
    "            metric_val_outputs = [AsDiscrete(argmax=True, to_onehot=self.hparams.out_channels)(i) for i in decollate_batch(y_hat)]\n",
    "            metric_val_labels = [AsDiscrete(to_onehot=self.hparams.out_channels)(i) for i in decollate_batch(y)]\n",
    "\n",
    "            # compute metric for current iteration\n",
    "            self.metric_fn(y_pred=metric_val_outputs, y=metric_val_labels)\n",
    "            metrics = self.metric_fn.aggregate(reduction=\"mean_batch\")\n",
    "            val_metric = torch.mean(metrics) # I used mean over all particle species as the metric. This can be explored.\n",
    "            self.val_metric += val_metric \n",
    "            self.num_val_batch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "        return {'val_metric': val_metric}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metric_per_epoch = self.val_metric/self.num_val_batch\n",
    "        #print(f\"Epoch {self.current_epoch} - Average Val Metric: {metric_per_epoch:.4f}\")\n",
    "        self.log('val_metric', metric_per_epoch, prog_bar=True, sync_dist=False) # sync_dist=True for distributed training\n",
    "        self.val_metric = 0\n",
    "        self.num_val_batch = 0\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = (48, 64, 80, 80)\n",
    "strides_pattern = (2, 2, 1)       \n",
    "num_res_units = 1\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "model = Model(channels=channels, strides=strides_pattern, num_res_units=num_res_units, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Check if CUDA is available and then count the GPUs\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "else:\n",
    "    print(\"No GPU available. Running on CPU.\")\n",
    "devices = list(range(num_gpus))\n",
    "print(devices)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    strategy=\"ddp_notebook\",  # 分散学習\n",
    "    accelerator=\"gpu\",\n",
    "    devices=devices,  # すべての GPU を使う\n",
    "    #devices = 1,\n",
    "    num_nodes=1,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # これが最速\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/y2023/m2311203/.conda/envs/ultralytics-env/lib/python3.11/site-packages/lightning/fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    strategy=\"ddp_notebook\",  # 不要なパラメータ探索を無効化\n",
    "    accelerator=\"gpu\",\n",
    "    devices=list(range(torch.cuda.device_count())),  # 全 GPU を使用\n",
    "    precision=16,  # FP16 で高速化\n",
    "    num_sanity_val_steps=0,  # 検証のオーバーヘッド削減\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDP is NOT initialized. Running in single GPU mode.\n"
     ]
    }
   ],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "if not dist.is_initialized():\n",
    "    print(\"DDP is NOT initialized. Running in single GPU mode.\")\n",
    "else:\n",
    "    print(f\"DDP initialized. Rank: {dist.get_rank()}, World Size: {dist.get_world_size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maaa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aaa' is not defined"
     ]
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/10\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/10\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/10\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/10\n",
      "Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/10\n",
      "Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/10\n",
      "Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/10\n",
      "Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/10\n",
      "Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/10\n",
      "Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 10 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:46\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:132\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/multiprocessing/connection.py:948\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ultralytics-env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "model.to(\"cuda\");\n",
    "\n",
    "TRAIN_DATA_DIR = \"../input/mask\"\n",
    "\n",
    "import json\n",
    "copick_config_path = TRAIN_DATA_DIR + \"/copick.config\"\n",
    "\n",
    "with open(copick_config_path) as f:\n",
    "    copick_config = json.load(f)\n",
    "\n",
    "copick_config['static_root'] = '../input/czii-cryo-et-object-identification/test/static'\n",
    "\n",
    "copick_test_config_path = 'copick_test.config'\n",
    "\n",
    "with open(copick_test_config_path, 'w') as outfile:\n",
    "    json.dump(copick_config, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copick\n",
    "\n",
    "root = copick.from_file(copick_test_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10\n",
    "tomo_type = \"denoised\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-random transforms to be cached\n",
    "inference_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\"], axcodes=\"RAS\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cc3d\n",
    "\n",
    "id_to_name = {1: \"apo-ferritin\", \n",
    "              2: \"beta-amylase\",\n",
    "              3: \"beta-galactosidase\", \n",
    "              4: \"ribosome\", \n",
    "              5: \"thyroglobulin\", \n",
    "              6: \"virus-like-particle\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CopickRun(name=TS_5_4, len(voxel_spacings)=None, len(picks)=None, len(meshes)=None, len(segmentations)=None) at 0x76cfa22db2d0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_tomogram is deprecated, use get_tomograms instead. Results may be incomplete\n",
      "Loading dataset: 100%|██████████| 98/98 [00:00<00:00, 147.56it/s]\n"
     ]
    }
   ],
   "source": [
    "BLOB_THRESHOLD = 500\n",
    "CERTAINTY_THRESHOLD = 0.5\n",
    "\n",
    "classes = [1, 2, 3, 4, 5, 6]\n",
    "with torch.no_grad():\n",
    "    location_df = []\n",
    "    for run in root.runs:\n",
    "        print(run)\n",
    "\n",
    "        tomo = run.get_voxel_spacing(10)\n",
    "        tomo = tomo.get_tomogram(tomo_type).numpy()\n",
    "\n",
    "\n",
    "\n",
    "        tomo_patches, coordinates  = extract_3d_patches_minimal_overlap([tomo], 96)\n",
    "\n",
    "        tomo_patched_data = [{\"image\": img} for img in tomo_patches]\n",
    "\n",
    "        tomo_ds = CacheDataset(data=tomo_patched_data, transform=inference_transforms, cache_rate=1.0)\n",
    "\n",
    "        pred_masks = []\n",
    "\n",
    "        for i in range(len(tomo_ds)):\n",
    "            input_tensor = tomo_ds[i]['image'].unsqueeze(0).to(\"cuda\")\n",
    "            model_output = model(input_tensor)\n",
    "\n",
    "            probs = torch.softmax(model_output[0], dim=0)\n",
    "            thresh_probs = probs > CERTAINTY_THRESHOLD\n",
    "            _, max_classes = thresh_probs.max(dim=0)\n",
    "\n",
    "            pred_masks.append(max_classes.cpu().numpy())\n",
    "            \n",
    "\n",
    "        reconstructed_mask = reconstruct_array(pred_masks, coordinates, tomo.shape)\n",
    "        \n",
    "        location = {}\n",
    "\n",
    "        for c in classes:\n",
    "            cc = cc3d.connected_components(reconstructed_mask == c)\n",
    "            stats = cc3d.statistics(cc)\n",
    "            zyx=stats['centroids'][1:]*10.012444 #https://www.kaggle.com/competitions/czii-cryo-et-object-identification/discussion/544895#3040071\n",
    "            zyx_large = zyx[stats['voxel_counts'][1:] > BLOB_THRESHOLD]\n",
    "            xyz =np.ascontiguousarray(zyx_large[:,::-1])\n",
    "\n",
    "            location[id_to_name[c]] = xyz\n",
    "\n",
    "\n",
    "        df = dict_to_df(location, run.name)\n",
    "        location_df.append(df)\n",
    "    \n",
    "    location_df = pd.concat(location_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df.insert(loc=0, column='id', value=np.arange(len(location_df)))\n",
    "location_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TS_5_4']\n",
      " TS_5_4 virus-like-particle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         particle_type    P   T  hit  miss   fp  precision    recall  \\\n",
       " 0         apo-ferritin   14  46    9    37    5   0.642857  0.195652   \n",
       " 1         beta-amylase   14  10    3     7   11   0.214286  0.300000   \n",
       " 2   beta-galactosidase   94  12    7     5   87   0.074468  0.583333   \n",
       " 3             ribosome   67  31   21    10   46   0.313433  0.677419   \n",
       " 4        thyroglobulin  176  30   27     3  149   0.153409  0.900000   \n",
       " 5  virus-like-particle   49  11   11     0   38   0.224490  1.000000   \n",
       " \n",
       "     f-beta4  weight  \n",
       " 0  0.204000       1  \n",
       " 1  0.293103       0  \n",
       " 2  0.416084       2  \n",
       " 3  0.634103       1  \n",
       " 4  0.699695       2  \n",
       " 5  0.831111       1  ,\n",
       " 0.55725317238851)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lb(location_df, f'{valid_dir}/overlay/ExperimentRuns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
