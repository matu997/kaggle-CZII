{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline UNet training + prediction/submission\n",
    "\n",
    "\n",
    "This is the notebook I cobbled together to wrap my head around this challenge.\n",
    "I don't garuantee that the results are great, only that it works from end-to-end. \n",
    "\n",
    "It trains a basic UNet and makes a submission. \n",
    "\n",
    "It's based on these three notebooks: \n",
    "\n",
    "1. [3D U-Net : Training Only](https://www.kaggle.com/code/ahsuna123/3d-u-net-training-only)\n",
    "2. [3D U-Net PyTorch Lightning distributed training](https://www.kaggle.com/code/zhuowenzhao11/3d-u-net-pytorch-lightning-distributed-training)\n",
    "3. [3d-unet using 2d image encoder](https://www.kaggle.com/code/hengck23/3d-unet-using-2d-image-encoder/notebook)\n",
    "\n",
    "\n",
    "I've pre-computed the input data and stored them as numpy arrays so they don't have to be extracted every time the notebooks is run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing offline deps\n",
    "\n",
    "As this is a code comp, there is no internet. \n",
    "So we have to do some silly things to get dependencies in here. \n",
    "Why is asciitree such a PITA? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:09:38.662016Z",
     "iopub.status.busy": "2024-11-19T21:09:38.661767Z",
     "iopub.status.idle": "2024-11-19T21:09:38.669631Z",
     "shell.execute_reply": "2024-11-19T21:09:38.668736Z",
     "shell.execute_reply.started": "2024-11-19T21:09:38.66199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "deps_path = '../input/czii-cryoet-dependencies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:11:14.621351Z",
     "iopub.status.busy": "2024-11-19T21:11:14.620928Z",
     "iopub.status.idle": "2024-11-19T21:11:47.939389Z",
     "shell.execute_reply": "2024-11-19T21:11:47.938583Z",
     "shell.execute_reply.started": "2024-11-19T21:11:14.621294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,  \n",
    "    AsDiscrete,  \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    NormalizeIntensityd,\n",
    "    RandCropByLabelClassesd,\n",
    ")\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some helper functions\n",
    "\n",
    "\n",
    "### Patching helper functions\n",
    "\n",
    "These are mostly used to split large volumes into smaller ones and stitch them back together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-11-19T21:11:47.941727Z",
     "iopub.status.busy": "2024-11-19T21:11:47.940809Z",
     "iopub.status.idle": "2024-11-19T21:11:47.956594Z",
     "shell.execute_reply": "2024-11-19T21:11:47.955741Z",
     "shell.execute_reply.started": "2024-11-19T21:11:47.941688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_patch_starts(dimension_size: int, patch_size: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Calculate the starting positions of patches along a single dimension\n",
    "    with minimal overlap to cover the entire dimension.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dimension_size : int\n",
    "        Size of the dimension\n",
    "    patch_size : int\n",
    "        Size of the patch in this dimension\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List[int]\n",
    "        List of starting positions for patches\n",
    "    \"\"\"\n",
    "    if dimension_size <= patch_size:\n",
    "        return [0]\n",
    "        \n",
    "    # Calculate number of patches needed\n",
    "    n_patches = np.ceil(dimension_size / patch_size)\n",
    "    \n",
    "    if n_patches == 1:\n",
    "        return [0]\n",
    "    \n",
    "    # Calculate overlap\n",
    "    total_overlap = (n_patches * patch_size - dimension_size) / (n_patches - 1)\n",
    "    \n",
    "    # Generate starting positions\n",
    "    positions = []\n",
    "    for i in range(int(n_patches)):\n",
    "        pos = int(i * (patch_size - total_overlap))\n",
    "        if pos + patch_size > dimension_size:\n",
    "            pos = dimension_size - patch_size\n",
    "        if pos not in positions:  # Avoid duplicates\n",
    "            positions.append(pos)\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def extract_3d_patches_minimal_overlap(arrays: List[np.ndarray], patch_size: int) -> Tuple[List[np.ndarray], List[Tuple[int, int, int]]]:\n",
    "    \"\"\"\n",
    "    Extract 3D patches from multiple arrays with minimal overlap to cover the entire array.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    arrays : List[np.ndarray]\n",
    "        List of input arrays, each with shape (m, n, l)\n",
    "    patch_size : int\n",
    "        Size of cubic patches (a x a x a)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    patches : List[np.ndarray]\n",
    "        List of all patches from all input arrays\n",
    "    coordinates : List[Tuple[int, int, int]]\n",
    "        List of starting coordinates (x, y, z) for each patch\n",
    "    \"\"\"\n",
    "    if not arrays or not isinstance(arrays, list):\n",
    "        raise ValueError(\"Input must be a non-empty list of arrays\")\n",
    "    \n",
    "    # Verify all arrays have the same shape\n",
    "    shape = arrays[0].shape\n",
    "    if not all(arr.shape == shape for arr in arrays):\n",
    "        raise ValueError(\"All input arrays must have the same shape\")\n",
    "    \n",
    "    if patch_size > min(shape):\n",
    "        raise ValueError(f\"patch_size ({patch_size}) must be smaller than smallest dimension {min(shape)}\")\n",
    "    \n",
    "    m, n, l = shape\n",
    "    patches = []\n",
    "    coordinates = []\n",
    "    \n",
    "    # Calculate starting positions for each dimension\n",
    "    x_starts = calculate_patch_starts(m, patch_size)\n",
    "    y_starts = calculate_patch_starts(n, patch_size)\n",
    "    z_starts = calculate_patch_starts(l, patch_size)\n",
    "    \n",
    "    # Extract patches from each array\n",
    "    for arr in arrays:\n",
    "        for x in x_starts:\n",
    "            for y in y_starts:\n",
    "                for z in z_starts:\n",
    "                    patch = arr[\n",
    "                        x:x + patch_size,\n",
    "                        y:y + patch_size,\n",
    "                        z:z + patch_size\n",
    "                    ]\n",
    "                    patches.append(patch)\n",
    "                    coordinates.append((x, y, z))\n",
    "    \n",
    "    return patches, coordinates\n",
    "\n",
    "# Note: I should probably averge the overlapping areas, \n",
    "# but here they are just overwritten by the most recent one. \n",
    "\n",
    "def reconstruct_array(patches: List[np.ndarray], \n",
    "                     coordinates: List[Tuple[int, int, int]], \n",
    "                     original_shape: Tuple[int, int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reconstruct array from patches.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    patches : List[np.ndarray]\n",
    "        List of patches to reconstruct from\n",
    "    coordinates : List[Tuple[int, int, int]]\n",
    "        Starting coordinates for each patch\n",
    "    original_shape : Tuple[int, int, int]\n",
    "        Shape of the original array\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Reconstructed array\n",
    "    \"\"\"\n",
    "    reconstructed = np.zeros(original_shape, dtype=np.int64)  # To track overlapping regions\n",
    "    \n",
    "    patch_size = patches[0].shape[0]\n",
    "    \n",
    "    for patch, (x, y, z) in zip(patches, coordinates):\n",
    "        reconstructed[\n",
    "            x:x + patch_size,\n",
    "            y:y + patch_size,\n",
    "            z:z + patch_size\n",
    "        ] = patch\n",
    "        \n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission helper functions\n",
    "\n",
    "These help with getting the submission in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-11-19T21:11:47.95787Z",
     "iopub.status.busy": "2024-11-19T21:11:47.957605Z",
     "iopub.status.idle": "2024-11-19T21:11:47.978432Z",
     "shell.execute_reply": "2024-11-19T21:11:47.977741Z",
     "shell.execute_reply.started": "2024-11-19T21:11:47.957844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dict_to_df(coord_dict, experiment_name):\n",
    "    \"\"\"\n",
    "    Convert dictionary of coordinates to pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coord_dict : dict\n",
    "        Dictionary where keys are labels and values are Nx3 coordinate arrays\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns ['x', 'y', 'z', 'label']\n",
    "    \"\"\"\n",
    "    # Create lists to store data\n",
    "    all_coords = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Process each label and its coordinates\n",
    "    for label, coords in coord_dict.items():\n",
    "        all_coords.append(coords)\n",
    "        all_labels.extend([label] * len(coords))\n",
    "    \n",
    "    # Concatenate all coordinates\n",
    "    all_coords = np.vstack(all_coords)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'experiment': experiment_name,\n",
    "        'particle_type': all_labels,\n",
    "        'x': all_coords[:, 0],\n",
    "        'y': all_coords[:, 1],\n",
    "        'z': all_coords[:, 2]\n",
    "    })\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:11:47.979657Z",
     "iopub.status.busy": "2024-11-19T21:11:47.979396Z",
     "iopub.status.idle": "2024-11-19T21:11:47.989983Z",
     "shell.execute_reply": "2024-11-19T21:11:47.989174Z",
     "shell.execute_reply.started": "2024-11-19T21:11:47.979632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = \"../input/create-numpy-dataset-exp-name\"\n",
    "TEST_DATA_DIR = \"../input/czii-cryo-et-object-identification\"\n",
    "valid_dir = '../input/czii-cryo-et-object-identification/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:11:47.99147Z",
     "iopub.status.busy": "2024-11-19T21:11:47.990874Z",
     "iopub.status.idle": "2024-11-19T21:12:03.216903Z",
     "shell.execute_reply": "2024-11-19T21:12:03.216155Z",
     "shell.execute_reply.started": "2024-11-19T21:11:47.991441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_names = ['TS_5_4', 'TS_69_2', 'TS_6_6', 'TS_73_6', 'TS_86_3', 'TS_99_9']\n",
    "valid_names = ['TS_6_4']\n",
    "\n",
    "train_files = []\n",
    "valid_files = []\n",
    "\n",
    "for name in train_names:\n",
    "    image = read_one_data(name, static_dir=f'{valid_dir}/static/ExperimentRuns')\n",
    "    label = np.load(f\"../input/mask/train_label_{name}.npy\")\n",
    "\n",
    "    train_files.append({\"image\": image, \"label\": label})\n",
    "    \n",
    "\n",
    "for name in valid_names:\n",
    "    image = read_one_data(name, static_dir=f'{valid_dir}/static/ExperimentRuns')\n",
    "    label = np.load(f\"../input/mask/train_label_{name}.npy\")\n",
    "\n",
    "    valid_files.append({\"image\": image, \"label\": label})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training dataloader\n",
    "\n",
    "I should probably find a way to create a dataloader that takes more batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:12:03.220954Z",
     "iopub.status.busy": "2024-11-19T21:12:03.220682Z",
     "iopub.status.idle": "2024-11-19T21:12:05.365905Z",
     "shell.execute_reply": "2024-11-19T21:12:05.364898Z",
     "shell.execute_reply.started": "2024-11-19T21:12:03.220928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, RandCropByLabelClassesd, EnsureTyped, RandAxisFlipd, SpatialPadd\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "import torch\n",
    "\n",
    "# Non-random transforms to be cached\n",
    "non_random_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")\n",
    "])\n",
    "\n",
    "raw_train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)\n",
    "\n",
    "my_num_samples = 1\n",
    "train_batch_size = 1\n",
    "\n",
    "# Random transforms to be applied during training\n",
    "random_transforms = Compose([\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=[32, 630, 630],  # 切り取りサイズ\n",
    "        num_classes=7,\n",
    "        num_samples=my_num_samples,\n",
    "    ),\n",
    "    SpatialPadd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        spatial_size=(32, 640, 640),\n",
    "        method=\"symmetric\",  # 中心的なパディング\n",
    "        mode=\"constant\",  # パディング値\n",
    "    ),\n",
    "    RandAxisFlipd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        prob=0.5,\n",
    "    ),\n",
    "    RandFlipd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        prob=0.5,\n",
    "        spatial_axis=[1]\n",
    "    ),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "train_ds = Dataset(data=raw_train_ds, transform=random_transforms)\n",
    "\n",
    "# DataLoader remains the same\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import Compose, RandCropByLabelClassesd, EnsureTyped, Resized\n",
    "from monai.data import Dataset, CacheDataset, DataLoader\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# 再現性のための設定\n",
    "set_determinism(seed=16)\n",
    "\n",
    "# ユニークな画像を保存するリスト（バイト列ではなくテンソルで保持する）\n",
    "unique_images = []\n",
    "\n",
    "# データローダーからユニークな画像を取得する関数\n",
    "def collect_unique_images(data_loader):\n",
    "    global unique_images\n",
    "    unique_hashes = set()  # 重複を防ぐためのハッシュセット\n",
    "    for batch in data_loader:\n",
    "        images = batch[\"image\"]  # 画像テンソルを取得\n",
    "        for image in images:\n",
    "            img_hash = hash(image.numpy().tobytes())  # ユニーク性を判定するためにハッシュ化\n",
    "            if img_hash not in unique_hashes:\n",
    "                unique_hashes.add(img_hash)\n",
    "                unique_images.append(image.numpy())  # ユニーク画像をリストに保存\n",
    "\n",
    "# ユニーク画像をグリッド形式で表示する関数\n",
    "def display_images(images, num_cols=5, title=\"unique images\"):\n",
    "    num_images = len(images)\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # 必要な行数を計算\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < num_images:\n",
    "            image = images[idx]\n",
    "            image = image[0, 15, :, :]  # 形状 (1, 32, 630, 630) -> (630, 630)\n",
    "            ax.imshow(image, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")  # 空白のプロット領域\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# データローダーから画像を収集して表示\n",
    "collect_unique_images(train_loader)\n",
    "print(f\"ユニークな画像の数: {len(unique_images)}\")\n",
    "display_images(unique_images, num_cols=5, title=\"unique images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cc3d\n",
    "from dataset import *\n",
    "from czii_helper import dotdict\n",
    "\n",
    "def probability_to_location(probability,cfg):\n",
    "    _,D,H,W = probability.shape\n",
    "\n",
    "    location={}\n",
    "    for p in PARTICLE:\n",
    "        p = dotdict(p)\n",
    "        l = p.label\n",
    "\n",
    "        cc, P = cc3d.connected_components(probability[l]>cfg.threshold[p.name], return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "        zyx=stats['centroids'][1:]*10\n",
    "        xyz = np.ascontiguousarray(zyx[:,::-1]) \n",
    "        location[p.name]=xyz\n",
    "        '''\n",
    "            j=1\n",
    "            z,y,x = np.where(cc==j)\n",
    "            z=z.mean()\n",
    "            y=y.mean()\n",
    "            x=x.mean()\n",
    "            print([x,y,z])\n",
    "        '''\n",
    "    return location\n",
    "\n",
    "def location_to_df(location):\n",
    "    location_df = []\n",
    "    for p in PARTICLE:\n",
    "        p = dotdict(p)\n",
    "        xyz = location[p.name]\n",
    "        if len(xyz)>0:\n",
    "            df = pd.DataFrame(data=xyz, columns=['x','y','z'])\n",
    "            #df.loc[:,'particle_type']= p.name\n",
    "            df.insert(loc=0, column='particle_type', value=p.name)\n",
    "            location_df.append(df)\n",
    "    if location_df:\n",
    "        location_df = pd.concat(location_df)\n",
    "    else:\n",
    "        location_df = pd.DataFrame()\n",
    "        print(\"location_df is empty, returning an empty DataFrame.\")\n",
    "    return location_df\n",
    "\n",
    "cfg = dotdict(\n",
    "    arch ='resnet34d',\n",
    "    checkpoint=\\\n",
    "    #'/kaggle/input/hengck-czii-cryo-et-weights-01/resnet34d-aug-noise-00003956.pth',\n",
    "       #  '/kaggle/input/hengck-czii-cryo-et-weights-01/resnet34d-00002300.pth',\n",
    "       # '/kaggle/input/hengck-czii-cryo-et-weights-01/00003531.pth',\n",
    "       \"../analyze/model.pth\",\n",
    "    threshold={ \n",
    "        'apo-ferritin': 0.05,\n",
    "        'beta-amylase': 0.05,\n",
    "        'beta-galactosidase': 0.05,\n",
    "        'ribosome': 0.05,\n",
    "        'thyroglobulin': 0.05,\n",
    "        'virus-like-particle': 0.05,\n",
    "    },\n",
    ")\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def do_one_eval(truth, predict, threshold):\n",
    "    P=len(predict)\n",
    "    T=len(truth)\n",
    "\n",
    "    if P==0:\n",
    "        hit=[[],[]]\n",
    "        miss=np.arange(T).tolist()\n",
    "        fp=[]\n",
    "        metric = [P,T,len(hit[0]),len(miss),len(fp)]\n",
    "        return hit, fp, miss, metric\n",
    "\n",
    "    if T==0:\n",
    "        hit=[[],[]]\n",
    "        fp=np.arange(P).tolist()\n",
    "        miss=[]\n",
    "        metric = [P,T,len(hit[0]),len(miss),len(fp)]\n",
    "        return hit, fp, miss, metric\n",
    "\n",
    "    #---\n",
    "    distance = predict.reshape(P,1,3)-truth.reshape(1,T,3)\n",
    "    distance = distance**2\n",
    "    distance = distance.sum(axis=2)\n",
    "    distance = np.sqrt(distance)\n",
    "    p_index, t_index = linear_sum_assignment(distance)\n",
    "\n",
    "    valid = distance[p_index, t_index] <= threshold\n",
    "    p_index = p_index[valid]\n",
    "    t_index = t_index[valid]\n",
    "    hit = [p_index.tolist(), t_index.tolist()]\n",
    "    miss = np.arange(T)\n",
    "    miss = miss[~np.isin(miss,t_index)].tolist()\n",
    "    fp = np.arange(P)\n",
    "    fp = fp[~np.isin(fp,p_index)].tolist()\n",
    "\n",
    "    metric = [P,T,len(hit[0]),len(miss),len(fp)] #for lb metric F-beta copmutation\n",
    "    return hit, fp, miss, metric\n",
    "\n",
    "\n",
    "def compute_lb(submit_df, overlay_dir):\n",
    "    valid_id = list(submit_df['experiment'].unique())\n",
    "    print(valid_id)\n",
    "\n",
    "    eval_df = []\n",
    "    for id in valid_id:\n",
    "        truth = read_one_truth(id, overlay_dir) #=f'{valid_dir}/overlay/ExperimentRuns')\n",
    "        id_df = submit_df[submit_df['experiment'] == id]\n",
    "        for p in PARTICLE:\n",
    "            p = dotdict(p)\n",
    "            print('\\r', id, p.name, end='', flush=True)\n",
    "            xyz_truth = truth[p.name]\n",
    "            xyz_predict = id_df[id_df['particle_type'] == p.name][['x', 'y', 'z']].values\n",
    "            hit, fp, miss, metric = do_one_eval(xyz_truth, xyz_predict, p.radius* 0.5)\n",
    "            eval_df.append(dotdict(\n",
    "                id=id, particle_type=p.name,\n",
    "                P=metric[0], T=metric[1], hit=metric[2], miss=metric[3], fp=metric[4],\n",
    "            ))\n",
    "    print('')\n",
    "    eval_df = pd.DataFrame(eval_df)\n",
    "    gb = eval_df.groupby('particle_type').agg('sum').drop(columns=['id'])\n",
    "    gb.loc[:, 'precision'] = gb['hit'] / gb['P']\n",
    "    gb.loc[:, 'precision'] = gb['precision'].fillna(0)\n",
    "    gb.loc[:, 'recall'] = gb['hit'] / gb['T']\n",
    "    gb.loc[:, 'recall'] = gb['recall'].fillna(0)\n",
    "    gb.loc[:, 'f-beta4'] = 17 * gb['precision'] * gb['recall'] / (16 * gb['precision'] + gb['recall'])\n",
    "    gb.loc[:, 'f-beta4'] = gb['f-beta4'].fillna(0)\n",
    "\n",
    "    gb = gb.sort_values('particle_type').reset_index(drop=False)\n",
    "    # https://www.kaggle.com/competitions/czii-cryo-et-object-identification/discussion/544895\n",
    "    gb.loc[:, 'weight'] = [1, 0, 2, 1, 2, 1]\n",
    "    lb_score = (gb['f-beta4'] * gb['weight']).sum() / gb['weight'].sum()\n",
    "    return gb, lb_score\n",
    "\n",
    "def printCV(valid_id,cfg,net):\n",
    "    net.output_type = ['infer']\n",
    "    submit_df = []\n",
    "    net.eval()\n",
    "    volume = read_one_data(valid_id[0], static_dir=f'{valid_dir}/static/ExperimentRuns')\n",
    "    D, H, W = volume.shape\n",
    "    probability = np.zeros((7, D, H, W), dtype=np.float32)\n",
    "    count = np.zeros((7, D, H, W), dtype=np.float32)\n",
    "    pad_volume = np.pad(volume, [[0, 0], [0, 640 - H], [0, 640 - W]], mode='constant', constant_values=0)\n",
    "\n",
    "    num_slice = 32\n",
    "    zz = list(range(0, D - num_slice, num_slice // 2)) + [D - num_slice]\n",
    "\n",
    "    for z in zz:\n",
    "        print('\\r', f'z:{z}', end='', flush=True)\n",
    "        image = pad_volume[z:z + num_slice]\n",
    "        batch = dotdict(\n",
    "            image=torch.from_numpy(image).unsqueeze(0),\n",
    "        )\n",
    "        with torch.amp.autocast('cuda', enabled=True):\n",
    "            with torch.no_grad():\n",
    "                output = net(batch)\n",
    "        prob = output['particle'][0].cpu().numpy()\n",
    "        probability[:, z:z + num_slice] += prob[:, :, :H, :W]\n",
    "        count[:, z:z + num_slice] += 1\n",
    "    probability = probability / (count + 0.0001)\n",
    "    location = probability_to_location(probability, cfg)\n",
    "    df = location_to_df(location)\n",
    "    df.insert(loc=0, column='experiment', value=valid_id[0])\n",
    "    submit_df.append(df)\n",
    "\n",
    "    num_volume = len(valid_id)\n",
    "    submit_df = pd.concat(submit_df)\n",
    "\n",
    "    submit_df.insert(loc=0, column='id', value=np.arange(len(submit_df)))\n",
    "    \n",
    "    gb, lb_score = compute_lb(submit_df, f'{valid_dir}/overlay/ExperimentRuns')\n",
    "\n",
    "    print(gb)\n",
    "    print('lb_score:', lb_score)\n",
    "\n",
    "    net.train()\n",
    "    net.output_type = ['infer', 'loss']\n",
    "    return probability\n",
    "\n",
    "def visualize_and_save(valid_id,output, save_path=\"output_plot.png\", title_prefix=\"Image\",show=True,index=0):\n",
    "    data_id = valid_names[0]\n",
    "    volume = read_one_data(valid_id[0], static_dir=f'{valid_dir}/static/ExperimentRuns')\n",
    "    mask = np.load(f'../input/mask/train_label_{data_id}.npy')\n",
    "\n",
    "    volume = volume[index]\n",
    "    mask = mask[index]\n",
    "    \n",
    "    # プロットの設定\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))  # 2行4列のグリッドを作成\n",
    "    axes = axes.ravel()  # 2D配列を1Dに変換して簡単にインデックスを操作できるようにする\n",
    "\n",
    "    for i in range(7):  # 最大7つの画像をプロット\n",
    "        ax = axes[i]  # 現在の軸を取得\n",
    "        img = output[i][index] # データを取得\n",
    "        im = ax.imshow(img, cmap='GnBu')  # データをプロット\n",
    "        ax.set_title(f\"{title_prefix} {i+1}\")  # 各プロットにタイトルを付ける\n",
    "        plt.colorbar(im, ax=ax)  # 各軸にカラーバーを追加\n",
    "    \n",
    "    #8枚目を画像とそのマスクで追加\n",
    "    ax = axes[7]\n",
    "    img = volume\n",
    "    im = ax.imshow(img, cmap='GnBu')  # データをプロット\n",
    "    #マスクを重ねる\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask[mask==0] = np.nan\n",
    "    im = ax.imshow(mask, cmap='Reds', alpha=0.5)  # データをプロット\n",
    "    ax.set_title(f\"{title_prefix} {7+1}\")  # 各プロットにタイトルを付ける\n",
    "    plt.colorbar(im, ax=ax)  # 各軸にカラーバーを追加\n",
    "\n",
    "\n",
    "    # 空のプロット（8個目が存在しない場合）を非表示にする\n",
    "    if len(axes) > 7:\n",
    "        axes[7].axis('off')\n",
    "\n",
    "    plt.tight_layout()  # プロットのレイアウトを自動調整\n",
    "\n",
    "    # 画像を保存\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')  # 高解像度で保存\n",
    "    print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "    #if show == True:\n",
    "    #    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2_for10 import Net,run_check_net\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = Net(pretrained=True,cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.output_type = ['infer','loss']\n",
    "net = net.to(device)\n",
    "# パラメータ設定\n",
    "num_epochs = 400 # エポック数\n",
    "learning_rate = 1e-3# 学習率\n",
    "model_save_path = '../model/model1.pth'  # 最終モデル保存ファイル\n",
    "\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "\n",
    "        batch[\"image\"] = batch[\"image\"].squeeze(1).to(device)\n",
    "        batch[\"label\"] = batch[\"label\"].squeeze(1).long().to(device)\n",
    "        with torch.amp.autocast('cuda', enabled=True):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(batch)\n",
    "            loss = outputs['mask_loss']\n",
    "        \n",
    "        for k, v in outputs.items():\n",
    "            if 'loss' in k:\n",
    "                print(f'{k:>32} : {v.item()} ')    \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        max_norm = 1.0\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm)\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % 25 == 0:\n",
    "        tmp = printCV(valid_names,cfg,net)\n",
    "        visualize_and_save(valid_names,tmp, save_path=f\"image/{epoch}.png\", title_prefix=\"Image\",show=True,index=62)\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path)\n",
    "print(\"Model saved to\", model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let there be gradients!\n",
    "\n",
    "Locally this config seems to train for about 1000 steps before the model starts overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:20.769975Z",
     "iopub.status.busy": "2024-11-19T21:32:20.769598Z",
     "iopub.status.idle": "2024-11-19T21:32:20.779771Z",
     "shell.execute_reply": "2024-11-19T21:32:20.779052Z",
     "shell.execute_reply.started": "2024-11-19T21:32:20.769933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval();\n",
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:20.78143Z",
     "iopub.status.busy": "2024-11-19T21:32:20.78116Z",
     "iopub.status.idle": "2024-11-19T21:32:20.820128Z",
     "shell.execute_reply": "2024-11-19T21:32:20.819279Z",
     "shell.execute_reply.started": "2024-11-19T21:32:20.781402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "copick_config_path = TRAIN_DATA_DIR + \"/copick.config\"\n",
    "\n",
    "with open(copick_config_path) as f:\n",
    "    copick_config = json.load(f)\n",
    "\n",
    "copick_config['static_root'] = '../input/czii-cryo-et-object-identification/test/static'\n",
    "\n",
    "copick_test_config_path = 'copick_test.config'\n",
    "\n",
    "with open(copick_test_config_path, 'w') as outfile:\n",
    "    json.dump(copick_config, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:20.82203Z",
     "iopub.status.busy": "2024-11-19T21:32:20.821406Z",
     "iopub.status.idle": "2024-11-19T21:32:21.592482Z",
     "shell.execute_reply": "2024-11-19T21:32:21.591544Z",
     "shell.execute_reply.started": "2024-11-19T21:32:20.821982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copick\n",
    "\n",
    "root = copick.from_file(copick_test_config_path)\n",
    "\n",
    "copick_user_name = \"copickUtils\"\n",
    "copick_segmentation_name = \"paintedPicks\"\n",
    "voxel_size = 10\n",
    "tomo_type = \"denoised\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:21.595036Z",
     "iopub.status.busy": "2024-11-19T21:32:21.593755Z",
     "iopub.status.idle": "2024-11-19T21:32:21.600315Z",
     "shell.execute_reply": "2024-11-19T21:32:21.599493Z",
     "shell.execute_reply.started": "2024-11-19T21:32:21.594993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Non-random transforms to be cached\n",
    "inference_transforms = Compose([\n",
    "    EnsureChannelFirstd(keys=[\"image\"], channel_dim=\"no_channel\"),\n",
    "    NormalizeIntensityd(keys=\"image\"),\n",
    "    Orientationd(keys=[\"image\"], axcodes=\"RAS\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:21.601913Z",
     "iopub.status.busy": "2024-11-19T21:32:21.601645Z",
     "iopub.status.idle": "2024-11-19T21:32:21.619239Z",
     "shell.execute_reply": "2024-11-19T21:32:21.61848Z",
     "shell.execute_reply.started": "2024-11-19T21:32:21.601886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cc3d\n",
    "\n",
    "id_to_name = {1: \"apo-ferritin\", \n",
    "              2: \"beta-amylase\",\n",
    "              3: \"beta-galactosidase\", \n",
    "              4: \"ribosome\", \n",
    "              5: \"thyroglobulin\", \n",
    "              6: \"virus-like-particle\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over test set\n",
    "\n",
    "\n",
    "Below we will: \n",
    "1. Read in a run\n",
    "2. Split it into patches of size (96, 96, 96)\n",
    "3. Create a dataset from the patches\n",
    "4. Predict the segmentation mask\n",
    "5. Glue the mask back together\n",
    "6. Find the connected components for each class\n",
    "7. Find the centroids of the connected components\n",
    "8. Add to the dataframe\n",
    "\n",
    "Then do this for all runs. \n",
    "\n",
    "This can probably be optimized quite a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:21.620928Z",
     "iopub.status.busy": "2024-11-19T21:32:21.620215Z",
     "iopub.status.idle": "2024-11-19T21:32:57.567719Z",
     "shell.execute_reply": "2024-11-19T21:32:57.566989Z",
     "shell.execute_reply.started": "2024-11-19T21:32:21.620899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BLOB_THRESHOLD = 500\n",
    "CERTAINTY_THRESHOLD = 0.5\n",
    "\n",
    "classes = [1, 2, 3, 4, 5, 6]\n",
    "with torch.no_grad():\n",
    "    location_df = []\n",
    "    for run in root.runs:\n",
    "        print(run)\n",
    "\n",
    "        tomo = run.get_voxel_spacing(10)\n",
    "        tomo = tomo.get_tomogram(tomo_type).numpy()\n",
    "\n",
    "\n",
    "\n",
    "        tomo_patches, coordinates  = extract_3d_patches_minimal_overlap([tomo], 96)\n",
    "\n",
    "        tomo_patched_data = [{\"image\": img} for img in tomo_patches]\n",
    "\n",
    "        tomo_ds = CacheDataset(data=tomo_patched_data, transform=inference_transforms, cache_rate=1.0)\n",
    "\n",
    "        pred_masks = []\n",
    "\n",
    "        for i in range(len(tomo_ds)):\n",
    "            input_tensor = tomo_ds[i]['image'].unsqueeze(0).to(\"cuda\")\n",
    "            model_output = model(input_tensor)\n",
    "\n",
    "            probs = torch.softmax(model_output[0], dim=0)\n",
    "            thresh_probs = probs > CERTAINTY_THRESHOLD\n",
    "            _, max_classes = thresh_probs.max(dim=0)\n",
    "\n",
    "            pred_masks.append(max_classes.cpu().numpy())\n",
    "            \n",
    "\n",
    "        reconstructed_mask = reconstruct_array(pred_masks, coordinates, tomo.shape)\n",
    "        \n",
    "        location = {}\n",
    "\n",
    "        for c in classes:\n",
    "            cc = cc3d.connected_components(reconstructed_mask == c)\n",
    "            stats = cc3d.statistics(cc)\n",
    "            zyx=stats['centroids'][1:]*10.012444 #https://www.kaggle.com/competitions/czii-cryo-et-object-identification/discussion/544895#3040071\n",
    "            zyx_large = zyx[stats['voxel_counts'][1:] > BLOB_THRESHOLD]\n",
    "            xyz =np.ascontiguousarray(zyx_large[:,::-1])\n",
    "\n",
    "            location[id_to_name[c]] = xyz\n",
    "\n",
    "\n",
    "        df = dict_to_df(location, run.name)\n",
    "        location_df.append(df)\n",
    "    \n",
    "    location_df = pd.concat(location_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:57.56956Z",
     "iopub.status.busy": "2024-11-19T21:32:57.568926Z",
     "iopub.status.idle": "2024-11-19T21:32:57.586987Z",
     "shell.execute_reply": "2024-11-19T21:32:57.586341Z",
     "shell.execute_reply.started": "2024-11-19T21:32:57.569519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "location_df.insert(loc=0, column='id', value=np.arange(len(location_df)))\n",
    "location_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:57.588622Z",
     "iopub.status.busy": "2024-11-19T21:32:57.588065Z",
     "iopub.status.idle": "2024-11-19T21:32:58.767534Z",
     "shell.execute_reply": "2024-11-19T21:32:58.766498Z",
     "shell.execute_reply.started": "2024-11-19T21:32:57.588582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:32:58.769243Z",
     "iopub.status.busy": "2024-11-19T21:32:58.76894Z",
     "iopub.status.idle": "2024-11-19T21:33:00.537355Z",
     "shell.execute_reply": "2024-11-19T21:33:00.53628Z",
     "shell.execute_reply.started": "2024-11-19T21:32:58.769214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/hengck-czii-cryo-et-01/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:33:00.540034Z",
     "iopub.status.busy": "2024-11-19T21:33:00.539136Z",
     "iopub.status.idle": "2024-11-19T21:33:00.54726Z",
     "shell.execute_reply": "2024-11-19T21:33:00.546595Z",
     "shell.execute_reply.started": "2024-11-19T21:33:00.539982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from czii_helper import *\n",
    "from dataset import *\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T21:49:29.23469Z",
     "iopub.status.busy": "2024-11-19T21:49:29.234206Z",
     "iopub.status.idle": "2024-11-19T21:49:30.805617Z",
     "shell.execute_reply": "2024-11-19T21:49:30.804545Z",
     "shell.execute_reply.started": "2024-11-19T21:49:29.234643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    MODE = 'submit'\n",
    "else:\n",
    "    MODE = 'local'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valid_dir ='../input/czii-cryo-et-object-identification/train'\n",
    "valid_id = ['TS_6_4', ]\n",
    "\n",
    "def do_one_eval(truth, predict, threshold):\n",
    "    P=len(predict)\n",
    "    T=len(truth)\n",
    "\n",
    "    if P==0:\n",
    "        hit=[[],[]]\n",
    "        miss=np.arange(T).tolist()\n",
    "        fp=[]\n",
    "        metric = [P,T,len(hit[0]),len(miss),len(fp)]\n",
    "        return hit, fp, miss, metric\n",
    "\n",
    "    if T==0:\n",
    "        hit=[[],[]]\n",
    "        fp=np.arange(P).tolist()\n",
    "        miss=[]\n",
    "        metric = [P,T,len(hit[0]),len(miss),len(fp)]\n",
    "        return hit, fp, miss, metric\n",
    "\n",
    "    #---\n",
    "    distance = predict.reshape(P,1,3)-truth.reshape(1,T,3)\n",
    "    distance = distance**2\n",
    "    distance = distance.sum(axis=2)\n",
    "    distance = np.sqrt(distance)\n",
    "    p_index, t_index = linear_sum_assignment(distance)\n",
    "\n",
    "    valid = distance[p_index, t_index] <= threshold\n",
    "    p_index = p_index[valid]\n",
    "    t_index = t_index[valid]\n",
    "    hit = [p_index.tolist(), t_index.tolist()]\n",
    "    miss = np.arange(T)\n",
    "    miss = miss[~np.isin(miss,t_index)].tolist()\n",
    "    fp = np.arange(P)\n",
    "    fp = fp[~np.isin(fp,p_index)].tolist()\n",
    "\n",
    "    metric = [P,T,len(hit[0]),len(miss),len(fp)] #for lb metric F-beta copmutation\n",
    "    return hit, fp, miss, metric\n",
    "\n",
    "\n",
    "def compute_lb(submit_df, overlay_dir):\n",
    "    valid_id = list(submit_df['experiment'].unique())\n",
    "    print(valid_id)\n",
    "\n",
    "    eval_df = []\n",
    "    for id in valid_id:\n",
    "        truth = read_one_truth(id, overlay_dir) #=f'{valid_dir}/overlay/ExperimentRuns')\n",
    "        id_df = submit_df[submit_df['experiment'] == id]\n",
    "        for p in PARTICLE:\n",
    "            p = dotdict(p)\n",
    "            print('\\r', id, p.name, end='', flush=True)\n",
    "            xyz_truth = truth[p.name]\n",
    "            xyz_predict = id_df[id_df['particle_type'] == p.name][['x', 'y', 'z']].values\n",
    "            hit, fp, miss, metric = do_one_eval(xyz_truth, xyz_predict, p.radius* 0.5)\n",
    "            eval_df.append(dotdict(\n",
    "                id=id, particle_type=p.name,\n",
    "                P=metric[0], T=metric[1], hit=metric[2], miss=metric[3], fp=metric[4],\n",
    "            ))\n",
    "    print('')\n",
    "    eval_df = pd.DataFrame(eval_df)\n",
    "    gb = eval_df.groupby('particle_type').agg('sum').drop(columns=['id'])\n",
    "    gb.loc[:, 'precision'] = gb['hit'] / gb['P']\n",
    "    gb.loc[:, 'precision'] = gb['precision'].fillna(0)\n",
    "    gb.loc[:, 'recall'] = gb['hit'] / gb['T']\n",
    "    gb.loc[:, 'recall'] = gb['recall'].fillna(0)\n",
    "    gb.loc[:, 'f-beta4'] = 17 * gb['precision'] * gb['recall'] / (16 * gb['precision'] + gb['recall'])\n",
    "    gb.loc[:, 'f-beta4'] = gb['f-beta4'].fillna(0)\n",
    "\n",
    "    gb = gb.sort_values('particle_type').reset_index(drop=False)\n",
    "    # https://www.kaggle.com/competitions/czii-cryo-et-object-identification/discussion/544895\n",
    "    gb.loc[:, 'weight'] = [1, 0, 2, 1, 2, 1]\n",
    "    lb_score = (gb['f-beta4'] * gb['weight']).sum() / gb['weight'].sum()\n",
    "    return gb, lb_score\n",
    "\n",
    "\n",
    "#debug\n",
    "if 1:\n",
    "    if MODE=='local':\n",
    "    #if 1:\n",
    "        submit_df=pd.read_csv(\n",
    "           'submission.csv'\n",
    "            # '/kaggle/input/hengck-czii-cryo-et-weights-01/submission.csv'\n",
    "        )\n",
    "        gb, lb_score = compute_lb(submit_df, f'{valid_dir}/overlay/ExperimentRuns')\n",
    "        print(gb)\n",
    "        print('lb_score:',lb_score)\n",
    "        print('')\n",
    "\n",
    "\n",
    "        #show one ----------------------------------\n",
    "        fig = plt.figure(figsize=(18, 8))\n",
    "\n",
    "        id = valid_id[0]\n",
    "        truth = read_one_truth(id,overlay_dir=f'{valid_dir}/overlay/ExperimentRuns')\n",
    "\n",
    "        submit_df = submit_df[submit_df['experiment']==id]\n",
    "        for p in PARTICLE:\n",
    "            p = dotdict(p)\n",
    "            xyz_truth = truth[p.name]\n",
    "            xyz_predict = submit_df[submit_df['particle_type']==p.name][['x','y','z']].values\n",
    "            hit, fp, miss, _ = do_one_eval(xyz_truth, xyz_predict, p.radius)\n",
    "            print(id, p.name)\n",
    "            print('\\t num truth   :',len(xyz_truth) )\n",
    "            print('\\t num predict :',len(xyz_predict) )\n",
    "            print('\\t num hit  :',len(hit[0]) )\n",
    "            print('\\t num fp   :',len(fp) )\n",
    "            print('\\t num miss :',len(miss) )\n",
    "\n",
    "            ax = fig.add_subplot(2, 3, p.label, projection='3d')\n",
    "            if hit[0]:\n",
    "                pt = xyz_predict[hit[0]]\n",
    "                ax.scatter(pt[:, 0], pt[:, 1], pt[:, 2], alpha=0.5, color='r')\n",
    "                pt = xyz_truth[hit[1]]\n",
    "                ax.scatter(pt[:,0], pt[:,1], pt[:,2], s=80, facecolors='none', edgecolors='r')\n",
    "            if fp:\n",
    "                pt = xyz_predict[fp]\n",
    "                ax.scatter(pt[:, 0], pt[:, 1], pt[:, 2], alpha=1, color='k')\n",
    "            if miss:\n",
    "                pt = xyz_truth[miss]\n",
    "                ax.scatter(pt[:, 0], pt[:, 1], pt[:, 2], s=160, alpha=1, facecolors='none', edgecolors='k')\n",
    "\n",
    "            ax.set_title(f'{p.name} ({p.difficulty})')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        #--- \n",
    "        zz=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10033515,
     "sourceId": 84969,
     "sourceType": "competition"
    },
    {
     "datasetId": 6052780,
     "sourceId": 9862305,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6040935,
     "sourceId": 9867543,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6058495,
     "sourceId": 9869730,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 206640467,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ultralytics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
